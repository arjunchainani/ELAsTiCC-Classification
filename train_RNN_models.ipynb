{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef94b41-958d-49c7-8540-8946fb201a79",
   "metadata": {},
   "source": [
    "# Train different RNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3beb889-dd3e-4f22-b4e6-5b31c55dbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "\n",
    "from train_RNN import train_model\n",
    "from train_ensemble import train_ensemble_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec39c601-78c5-40ab-a6b0-503fb3714b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "batch_size=1024\n",
    "learning_rate=5e-4\n",
    "latent_size=64\n",
    "max_class_count=30000 \n",
    "train_dir=Path(\"processed/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa48704-231e-4563-a887-7da0b2bec19d",
   "metadata": {},
   "source": [
    "## Train the base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a90ba3-edec-41ef-9b8d-416c2b32cdc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha=0\n",
    "model_dir=Path(f\"models/lsst_alpha_{alpha}\")\n",
    "\n",
    "train_model(num_epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate, \n",
    "            latent_size=latent_size, \n",
    "            alpha=alpha, \n",
    "            max_class_count=max_class_count, \n",
    "            train_dir=train_dir, \n",
    "            model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f231c42-5ef2-4b21-8312-25b1a1529433",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from disc...\n",
      "Summary of all training data\n",
      "Total sample count = 1081614\n",
      "            Class   Count\n",
      "0             AGN   76258\n",
      "1            CART    8207\n",
      "2         Cepheid   13771\n",
      "3     Delta Scuti   20650\n",
      "4     Dwarf Novae    8025\n",
      "5              EB   66454\n",
      "6            ILOT    7461\n",
      "7              KN    4426\n",
      "8   M-dwarf Flare    1859\n",
      "9            PISN   63586\n",
      "10       RR Lyrae   14033\n",
      "11           SLSN   66088\n",
      "12        SNI91bg   28637\n",
      "13           SNII  301544\n",
      "14           SNIa  120739\n",
      "15          SNIax   28030\n",
      "16         SNIb/c  168254\n",
      "17            TDE   66000\n",
      "18          uLens   17592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting dictionaries to arrays: 100%|██████████| 1081614/1081614 [00:06<00:00, 162688.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of training data used\n",
      "            Class  Count\n",
      "0             AGN  30000\n",
      "1            CART   8207\n",
      "2         Cepheid  13771\n",
      "3     Delta Scuti  20650\n",
      "4     Dwarf Novae   8025\n",
      "5              EB  30000\n",
      "6            ILOT   7461\n",
      "7              KN   4426\n",
      "8   M-dwarf Flare   1859\n",
      "9            PISN  30000\n",
      "10       RR Lyrae  14033\n",
      "11           SLSN  30000\n",
      "12        SNI91bg  28637\n",
      "13           SNII  30000\n",
      "14           SNIa  30000\n",
      "15          SNIax  28030\n",
      "16         SNIb/c  30000\n",
      "17            TDE  30000\n",
      "18          uLens  17592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 17:31:06.287063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31127 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:16:00.0, compute capability: 7.0\n",
      "2024-06-20 17:31:06.288927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31127 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS Input Dim: 5 | Static Input Dim: 23 | Output Dim: 26\n",
      "\n",
      "Start of epoch 0:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 11792.40it/s]\n",
      "Training Model:   0%|          | 0/383 [00:00<?, ?it/s]2024-06-20 17:31:58.044511: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_18/output/_21'\n",
      "2024-06-20 17:31:58.540400: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:467] Loaded cuDNN version 90000\n",
      "2024-06-20 17:31:59.126267: I external/local_xla/xla/service/service.cc:168] XLA service 0x152e98c086a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-20 17:31:59.126296: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-06-20 17:31:59.126300: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-06-20 17:31:59.144600: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718919119.260542   40540 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "Training Model:  99%|█████████▉| 380/383 [00:22<00:00, 16.58it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.2780\n",
      "Time taken: 64.68s\n",
      "Best model is at epoch 0 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 1:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 11912.64it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:22<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.2014\n",
      "Time taken: 64.59s\n",
      "Best model is at epoch 1 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 2:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 12134.86it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:28<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1680\n",
      "Time taken: 70.15s\n",
      "Best model is at epoch 2 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 3:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12220.38it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:25<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1543\n",
      "Time taken: 66.44s\n",
      "Best model is at epoch 3 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 4:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12423.49it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:13<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1781\n",
      "Time taken: 53.72s\n",
      "==========\n",
      "\n",
      "Start of epoch 5:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12405.96it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:09<00:00, 40.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.2191\n",
      "Time taken: 48.65s\n",
      "==========\n",
      "\n",
      "Start of epoch 6:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12471.12it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:18<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1552\n",
      "Time taken: 58.18s\n",
      "==========\n",
      "\n",
      "Start of epoch 7:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 11983.69it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:17<00:00, 22.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1510\n",
      "Time taken: 58.87s\n",
      "Best model is at epoch 7 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 8:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12235.45it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:20<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1361\n",
      "Time taken: 61.60s\n",
      "Best model is at epoch 8 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 9:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12176.38it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:24<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1202\n",
      "Time taken: 66.72s\n",
      "Best model is at epoch 9 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 10:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12275.07it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:19<00:00, 19.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1284\n",
      "Time taken: 61.09s\n",
      "==========\n",
      "\n",
      "Start of epoch 11:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 12046.33it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:21<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1210\n",
      "Time taken: 63.32s\n",
      "==========\n",
      "\n",
      "Start of epoch 12:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12179.10it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:15<00:00, 24.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1434\n",
      "Time taken: 56.68s\n",
      "==========\n",
      "\n",
      "Start of epoch 13:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12422.36it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:14<00:00, 26.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1467\n",
      "Time taken: 54.60s\n",
      "==========\n",
      "\n",
      "Start of epoch 14:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12362.79it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:13<00:00, 27.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1496\n",
      "Time taken: 53.67s\n",
      "==========\n",
      "\n",
      "Start of epoch 15:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12432.60it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:22<00:00, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1115\n",
      "Time taken: 62.77s\n",
      "Best model is at epoch 15 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 16:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12280.85it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:11<00:00, 33.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1714\n",
      "Time taken: 51.75s\n",
      "==========\n",
      "\n",
      "Start of epoch 17:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 12106.82it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:26<00:00, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1009\n",
      "Time taken: 67.94s\n",
      "Best model is at epoch 17 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 18:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 12102.55it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:22<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1054\n",
      "Time taken: 63.80s\n",
      "==========\n",
      "\n",
      "Start of epoch 19:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12190.34it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:29<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0882\n",
      "Time taken: 70.92s\n",
      "Best model is at epoch 19 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 20:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12250.01it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:14<00:00, 26.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1368\n",
      "Time taken: 55.40s\n",
      "==========\n",
      "\n",
      "Start of epoch 21:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 12023.67it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:11<00:00, 33.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1630\n",
      "Time taken: 52.79s\n",
      "==========\n",
      "\n",
      "Start of epoch 22:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12306.60it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:26<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0904\n",
      "Time taken: 67.63s\n",
      "==========\n",
      "\n",
      "Start of epoch 23:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12444.83it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:10<00:00, 36.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1751\n",
      "Time taken: 49.98s\n",
      "==========\n",
      "\n",
      "Start of epoch 24:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 12020.79it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:24<00:00, 15.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0902\n",
      "Time taken: 67.31s\n",
      "==========\n",
      "\n",
      "Start of epoch 25:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12200.78it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:15<00:00, 24.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1233\n",
      "Time taken: 56.60s\n",
      "==========\n",
      "\n",
      "Start of epoch 26:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12407.48it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:19<00:00, 19.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1028\n",
      "Time taken: 59.53s\n",
      "==========\n",
      "\n",
      "Start of epoch 27:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12553.46it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:16<00:00, 23.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1155\n",
      "Time taken: 55.71s\n",
      "==========\n",
      "\n",
      "Start of epoch 28:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12398.39it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:20<00:00, 18.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0977\n",
      "Time taken: 60.17s\n",
      "==========\n",
      "\n",
      "Start of epoch 29:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 12041.92it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:30<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0707\n",
      "Time taken: 72.56s\n",
      "Best model is at epoch 29 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 30:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12151.00it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:11<00:00, 33.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1555\n",
      "Time taken: 52.07s\n",
      "==========\n",
      "\n",
      "Start of epoch 31:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12619.01it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:26<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0794\n",
      "Time taken: 65.76s\n",
      "==========\n",
      "\n",
      "Start of epoch 32:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12414.21it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:09<00:00, 39.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1838\n",
      "Time taken: 48.67s\n",
      "==========\n",
      "\n",
      "Start of epoch 33:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model:  99%|█████████▉| 380/383 [00:09<00:00, 40.99it/s], 12513.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1915\n",
      "Time taken: 50.48s\n",
      "==========\n",
      "\n",
      "Start of epoch 35:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 12107.95it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:09<00:00, 42.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1987\n",
      "Time taken: 49.75s\n",
      "==========\n",
      "\n",
      "Start of epoch 36:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12414.38it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:23<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0828\n",
      "Time taken: 63.81s\n",
      "==========\n",
      "\n",
      "Start of epoch 37:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12419.78it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:25<00:00, 14.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0737\n",
      "Time taken: 66.79s\n",
      "==========\n",
      "\n",
      "Start of epoch 38:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12457.83it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:09<00:00, 41.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1900\n",
      "Time taken: 48.60s\n",
      "==========\n",
      "\n",
      "Start of epoch 39:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 11998.70it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:18<00:00, 20.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0972\n",
      "Time taken: 60.58s\n",
      "==========\n",
      "\n",
      "Start of epoch 40:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12211.71it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:19<00:00, 19.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0897\n",
      "Time taken: 61.03s\n",
      "==========\n",
      "\n",
      "Start of epoch 41:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation:  78%|███████▊  | 303702/388764 [00:24<00:06, 12265.44it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 12092.57it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:24<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0701\n",
      "Time taken: 66.44s\n",
      "Best model is at epoch 46 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 47:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12285.37it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:15<00:00, 24.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: nan\n",
      "Time taken: 56.37s\n",
      "Best model is at epoch 47 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 48:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 12092.03it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:25<00:00, 15.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: nan\n",
      "Time taken: 67.17s\n",
      "==========\n",
      "\n",
      "Start of epoch 49:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12426.39it/s]\n",
      "Training Model:  99%|█████████▉| 380/383 [00:09<00:00, 41.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: nan\n",
      "Time taken: 48.59s\n",
      "==========\n",
      "Running inference for validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 3927/3927 [00:00<00:00, 11302.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 3s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "alpha=0.5\n",
    "model_dir=Path(f\"models/lsst_alpha_{alpha}\")\n",
    "\n",
    "train_model(num_epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate, \n",
    "            latent_size=latent_size, \n",
    "            alpha=alpha, \n",
    "            max_class_count=max_class_count, \n",
    "            train_dir=train_dir, \n",
    "            model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c72bb8-e7cc-4f87-8338-f99cc6c9223c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from disc...\n",
      "Summary of all training data\n",
      "Total sample count = 1081614\n",
      "            Class   Count\n",
      "0             AGN   76258\n",
      "1            CART    8207\n",
      "2         Cepheid   13771\n",
      "3     Delta Scuti   20650\n",
      "4     Dwarf Novae    8025\n",
      "5              EB   66454\n",
      "6            ILOT    7461\n",
      "7              KN    4426\n",
      "8   M-dwarf Flare    1859\n",
      "9            PISN   63586\n",
      "10       RR Lyrae   14033\n",
      "11           SLSN   66088\n",
      "12        SNI91bg   28637\n",
      "13           SNII  301544\n",
      "14           SNIa  120739\n",
      "15          SNIax   28030\n",
      "16         SNIb/c  168254\n",
      "17            TDE   66000\n",
      "18          uLens   17592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting dictionaries to arrays: 100%|██████████| 1081614/1081614 [00:07<00:00, 152822.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of training data used\n",
      "            Class  Count\n",
      "0             AGN  30000\n",
      "1            CART   8207\n",
      "2         Cepheid  13771\n",
      "3     Delta Scuti  20650\n",
      "4     Dwarf Novae   8025\n",
      "5              EB  30000\n",
      "6            ILOT   7461\n",
      "7              KN   4426\n",
      "8   M-dwarf Flare   1859\n",
      "9            PISN  30000\n",
      "10       RR Lyrae  14033\n",
      "11           SLSN  30000\n",
      "12        SNI91bg  28637\n",
      "13           SNII  30000\n",
      "14           SNIa  30000\n",
      "15          SNIax  28030\n",
      "16         SNIb/c  30000\n",
      "17            TDE  30000\n",
      "18          uLens  17592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 06:26:02.206255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31127 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2024-06-21 06:26:02.207734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31127 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b3:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS Input Dim: 5 | Static Input Dim: 23 | Output Dim: 26\n",
      "\n",
      "Start of epoch 0:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:34<00:00, 11365.56it/s]\n",
      "Training Model:   0%|          | 0/384 [00:00<?, ?it/s]2024-06-21 06:26:57.540534: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_18/output/_21'\n",
      "2024-06-21 06:26:58.144408: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:467] Loaded cuDNN version 90000\n",
      "2024-06-21 06:26:59.382396: I external/local_xla/xla/service/service.cc:168] XLA service 0x153bda420a10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-21 06:26:59.382424: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-06-21 06:26:59.382428: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-06-21 06:26:59.401081: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718965619.566381   36022 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "Training Model:  99%|█████████▉| 380/384 [00:24<00:00, 15.55it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1407\n",
      "Time taken: 68.04s\n",
      "Best model is at epoch 0 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 1:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12458.89it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:12<00:00, 29.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1046\n",
      "Time taken: 52.42s\n",
      "Best model is at epoch 1 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 2:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12292.09it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:20<00:00, 18.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0944\n",
      "Time taken: 61.08s\n",
      "Best model is at epoch 2 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 3:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12184.07it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:14<00:00, 26.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0922\n",
      "Time taken: 54.81s\n",
      "Best model is at epoch 3 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 4:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12275.19it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:14<00:00, 25.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0853\n",
      "Time taken: 54.68s\n",
      "Best model is at epoch 4 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 5:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:29<00:00, 13129.56it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:15<00:00, 24.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0804\n",
      "Time taken: 53.29s\n",
      "Best model is at epoch 5 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 6:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12779.20it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:17<00:00, 21.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0733\n",
      "Time taken: 57.41s\n",
      "Best model is at epoch 6 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 7:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:29<00:00, 13223.85it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:16<00:00, 22.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0732\n",
      "Time taken: 54.97s\n",
      "Best model is at epoch 7 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 8:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12957.49it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:29<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0584\n",
      "Time taken: 68.09s\n",
      "Best model is at epoch 8 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 9:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12602.06it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:13<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0809\n",
      "Time taken: 52.37s\n",
      "==========\n",
      "\n",
      "Start of epoch 10:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12739.09it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:10<00:00, 35.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0911\n",
      "Time taken: 49.29s\n",
      "==========\n",
      "\n",
      "Start of epoch 11:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:29<00:00, 13273.76it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:22<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0616\n",
      "Time taken: 61.28s\n",
      "==========\n",
      "\n",
      "Start of epoch 12:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12914.37it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:13<00:00, 27.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0761\n",
      "Time taken: 52.04s\n",
      "==========\n",
      "\n",
      "Start of epoch 13:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:32<00:00, 11989.33it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:18<00:00, 20.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0630\n",
      "Time taken: 60.25s\n",
      "==========\n",
      "\n",
      "Start of epoch 14:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12443.59it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:20<00:00, 18.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0574\n",
      "Time taken: 61.31s\n",
      "Best model is at epoch 14 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 15:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12534.75it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:21<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0543\n",
      "Time taken: 61.76s\n",
      "Best model is at epoch 15 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 16:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12627.79it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:28<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0449\n",
      "Time taken: 68.45s\n",
      "Best model is at epoch 16 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 17:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12670.76it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:09<00:00, 41.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1065\n",
      "Time taken: 47.83s\n",
      "==========\n",
      "\n",
      "Start of epoch 18:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12390.44it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:18<00:00, 21.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0604\n",
      "Time taken: 59.10s\n",
      "==========\n",
      "\n",
      "Start of epoch 19:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12432.17it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:09<00:00, 40.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0979\n",
      "Time taken: 49.08s\n",
      "==========\n",
      "\n",
      "Start of epoch 20:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12499.82it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:28<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0467\n",
      "Time taken: 69.08s\n",
      "==========\n",
      "\n",
      "Start of epoch 21:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12554.37it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:18<00:00, 20.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0556\n",
      "Time taken: 58.49s\n",
      "==========\n",
      "\n",
      "Start of epoch 22:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12590.80it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:16<00:00, 23.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0608\n",
      "Time taken: 55.39s\n",
      "==========\n",
      "\n",
      "Start of epoch 23:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12622.17it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:20<00:00, 18.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0499\n",
      "Time taken: 59.96s\n",
      "==========\n",
      "\n",
      "Start of epoch 24:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12708.22it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:28<00:00, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0384\n",
      "Time taken: 68.63s\n",
      "Best model is at epoch 24 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 25:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:29<00:00, 13061.98it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:17<00:00, 22.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0554\n",
      "Time taken: 56.31s\n",
      "==========\n",
      "\n",
      "Start of epoch 26:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:29<00:00, 13106.59it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:29<00:00, 12.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0364\n",
      "Time taken: 68.37s\n",
      "Best model is at epoch 26 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 27:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12800.22it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:18<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0501\n",
      "Time taken: 58.02s\n",
      "==========\n",
      "\n",
      "Start of epoch 28:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12691.85it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:27<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0368\n",
      "Time taken: 67.07s\n",
      "==========\n",
      "\n",
      "Start of epoch 29:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12603.45it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:24<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0399\n",
      "Time taken: 64.18s\n",
      "==========\n",
      "\n",
      "Start of epoch 30:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12747.17it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:20<00:00, 18.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0442\n",
      "Time taken: 60.56s\n",
      "==========\n",
      "\n",
      "Start of epoch 31:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:29<00:00, 13295.68it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:16<00:00, 23.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0545\n",
      "Time taken: 54.27s\n",
      "==========\n",
      "\n",
      "Start of epoch 32:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12897.59it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:28<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0342\n",
      "Time taken: 67.19s\n",
      "Best model is at epoch 32 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 33:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12609.57it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:15<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0565\n",
      "Time taken: 54.66s\n",
      "==========\n",
      "\n",
      "Start of epoch 34:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12333.01it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:14<00:00, 26.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0585\n",
      "Time taken: 55.42s\n",
      "==========\n",
      "\n",
      "Start of epoch 35:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12399.16it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:08<00:00, 42.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0983\n",
      "Time taken: 48.86s\n",
      "==========\n",
      "\n",
      "Start of epoch 36:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12688.10it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:21<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0441\n",
      "Time taken: 60.74s\n",
      "==========\n",
      "\n",
      "Start of epoch 37:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12584.58it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:21<00:00, 17.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0434\n",
      "Time taken: 60.95s\n",
      "==========\n",
      "\n",
      "Start of epoch 38:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12641.89it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:28<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0317\n",
      "Time taken: 68.48s\n",
      "Best model is at epoch 38 Saving\n",
      "==========\n",
      "\n",
      "Start of epoch 39:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12590.98it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:08<00:00, 43.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1024\n",
      "Time taken: 47.51s\n",
      "==========\n",
      "\n",
      "Start of epoch 40:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12735.89it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:25<00:00, 15.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0362\n",
      "Time taken: 64.86s\n",
      "==========\n",
      "\n",
      "Start of epoch 41:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:29<00:00, 13228.84it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:21<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0407\n",
      "Time taken: 59.73s\n",
      "==========\n",
      "\n",
      "Start of epoch 42:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:29<00:00, 12972.10it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:24<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0354\n",
      "Time taken: 63.25s\n",
      "==========\n",
      "\n",
      "Start of epoch 43:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12521.66it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:17<00:00, 21.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0478\n",
      "Time taken: 57.12s\n",
      "==========\n",
      "\n",
      "Start of epoch 44:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12663.78it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:20<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0413\n",
      "Time taken: 59.68s\n",
      "==========\n",
      "\n",
      "Start of epoch 45:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:29<00:00, 13039.49it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:15<00:00, 23.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0513\n",
      "Time taken: 54.93s\n",
      "==========\n",
      "\n",
      "Start of epoch 46:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:29<00:00, 13212.04it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:21<00:00, 17.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0381\n",
      "Time taken: 60.03s\n",
      "==========\n",
      "\n",
      "Start of epoch 47:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:30<00:00, 12719.09it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:15<00:00, 24.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0510\n",
      "Time taken: 54.77s\n",
      "==========\n",
      "\n",
      "Start of epoch 48:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12243.56it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:16<00:00, 23.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0493\n",
      "Time taken: 57.20s\n",
      "==========\n",
      "\n",
      "Start of epoch 49:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:31<00:00, 12214.88it/s]\n",
      "Training Model:  99%|█████████▉| 380/384 [00:25<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.0325\n",
      "Time taken: 67.13s\n",
      "==========\n",
      "Running inference for validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 3927/3927 [00:00<00:00, 11178.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 2s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "alpha=0.75\n",
    "model_dir=Path(f\"models/lsst_alpha_{alpha}\")\n",
    "\n",
    "train_model(num_epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate, \n",
    "            latent_size=latent_size, \n",
    "            alpha=alpha, \n",
    "            max_class_count=max_class_count, \n",
    "            train_dir=train_dir, \n",
    "            model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea95c2-f692-49df-bb7d-8ae6a04b8285",
   "metadata": {},
   "source": [
    "## Train the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e21b5550-fcd7-4e55-8c04-f169ceeaf53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models/lsst_alpha_0/best_model.h5\n",
      "Loading models/lsst_alpha_0.5/lstm_epoch_46.h5\n",
      "Loading models/lsst_alpha_0.75/best_model.h5\n"
     ]
    }
   ],
   "source": [
    "alpha=0\n",
    "model_dir=Path(f\"models/ensemble\")\n",
    "\n",
    "model_paths = [\"models/lsst_alpha_0/best_model.h5\", \"models/lsst_alpha_0.5/lstm_epoch_46.h5\", \"models/lsst_alpha_0.75/best_model.h5\"]\n",
    "models = []\n",
    "for i, path in enumerate(model_paths):\n",
    "\n",
    "    print(f\"Loading {path}\")\n",
    "    loaded_model = keras.models.load_model(path, compile=False)\n",
    "    loaded_model._name = f\"model_{i}\"\n",
    "\n",
    "    for layer in loaded_model.layers:\n",
    "        layer._name = layer._name + str(f\"_{i}\")\n",
    "    models.append(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c84a978-3cb6-4b85-be63-1b6cc9dabe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from disc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model:   0%|          | 0/384 [02:36<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of all training data\n",
      "Total sample count = 1081614\n",
      "            Class   Count\n",
      "0             AGN   76258\n",
      "1            CART    8207\n",
      "2         Cepheid   13771\n",
      "3     Delta Scuti   20650\n",
      "4     Dwarf Novae    8025\n",
      "5              EB   66454\n",
      "6            ILOT    7461\n",
      "7              KN    4426\n",
      "8   M-dwarf Flare    1859\n",
      "9            PISN   63586\n",
      "10       RR Lyrae   14033\n",
      "11           SLSN   66088\n",
      "12        SNI91bg   28637\n",
      "13           SNII  301544\n",
      "14           SNIa  120739\n",
      "15          SNIax   28030\n",
      "16         SNIb/c  168254\n",
      "17            TDE   66000\n",
      "18          uLens   17592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting dictionaries to arrays: 100%|██████████| 1081614/1081614 [00:06<00:00, 162019.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of training data used\n",
      "            Class  Count\n",
      "0             AGN  30000\n",
      "1            CART   8207\n",
      "2         Cepheid  13771\n",
      "3     Delta Scuti  20650\n",
      "4     Dwarf Novae   8025\n",
      "5              EB  30000\n",
      "6            ILOT   7461\n",
      "7              KN   4426\n",
      "8   M-dwarf Flare   1859\n",
      "9            PISN  30000\n",
      "10       RR Lyrae  14033\n",
      "11           SLSN  30000\n",
      "12        SNI91bg  28637\n",
      "13           SNII  30000\n",
      "14           SNIa  30000\n",
      "15          SNIax  28030\n",
      "16         SNIb/c  30000\n",
      "17            TDE  30000\n",
      "18          uLens  17592\n",
      "TS Input Dim: 5 | Static Input Dim: 23 | Output Dim: 26\n",
      "Model: \"ensemble_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_0 (Functional)        (None, 26)                122294    \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 26)                122294    \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  1378      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245966 (960.80 KB)\n",
      "Trainable params: 245966 (960.80 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Start of epoch 0:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TS Data Augmentation: 100%|██████████| 388764/388764 [00:33<00:00, 11609.06it/s]\n",
      "Training Model:   0%|          | 0/384 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/jet/home/vshah4/ELAsTiCC-Classification/train_RNN.py\", line 58, in train_step  *\n        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients  **\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 638, in apply_gradients\n        self.build(trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\", line 145, in build\n        self.add_variable_from_reference(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1125, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 513, in add_variable_from_reference\n        variable = tf.Variable(\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_ensemble_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_class_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_class_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ELAsTiCC-Classification/train_ensemble.py:142\u001b[0m, in \u001b[0;36mtrain_ensemble_model\u001b[0;34m(models, num_epochs, batch_size, learning_rate, max_class_count, train_dir, model_dir)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Iterate over the batches of the dataset.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (x_ts_batch_train, x_static_batch_train, y_batch_train, a_class_batch_train) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataset):\n\u001b[0;32m--> 142\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_ts_batch_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_static_batch_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     train_loss_values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(loss_value))\n\u001b[1;32m    144\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/tmp/__autograph_generated_fileoettwpso.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(x_ts, x_static, y, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(criterion), (ag__\u001b[38;5;241m.\u001b[39mld(y), ag__\u001b[38;5;241m.\u001b[39mld(logits)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m grads \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss_value), ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrainable_weights), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py:1223\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1222\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py:638\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(scope_name):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minit_scope():\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;66;03m# Lift variable creation to init scope to avoid environment\u001b[39;00m\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;66;03m# issues.\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m optimizer_utils\u001b[38;5;241m.\u001b[39mfilter_empty_gradients(\n\u001b[1;32m    640\u001b[0m         grads_and_vars\n\u001b[1;32m    641\u001b[0m     )\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(grads_and_vars)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;66;03m# Check again after filtering gradients.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py:145\u001b[0m, in \u001b[0;36mAdam.build\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_velocities \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m var_list:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_momentums\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 145\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_variable_from_reference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_variable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_velocities\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_variable_from_reference(\n\u001b[1;32m    151\u001b[0m             model_variable\u001b[38;5;241m=\u001b[39mvar, variable_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m         )\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamsgrad:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py:1125\u001b[0m, in \u001b[0;36mOptimizer.add_variable_from_reference\u001b[0;34m(self, model_variable, variable_name, shape, initial_value)\u001b[0m\n\u001b[1;32m   1123\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mcolocate_vars_with(model_variable):\n\u001b[0;32m-> 1125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_variable_from_reference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_value\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py:513\u001b[0m, in \u001b[0;36m_BaseOptimizer.add_variable_from_reference\u001b[0;34m(self, model_variable, variable_name, shape, initial_value)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    512\u001b[0m         initial_value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mzeros(shape, dtype\u001b[38;5;241m=\u001b[39mmodel_variable\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 513\u001b[0m variable \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvariable_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_variable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shared_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_variable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables\u001b[38;5;241m.\u001b[39mappend(variable)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m variable\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/jet/home/vshah4/ELAsTiCC-Classification/train_RNN.py\", line 58, in train_step  *\n        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients  **\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 638, in apply_gradients\n        self.build(trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\", line 145, in build\n        self.add_variable_from_reference(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1125, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 513, in add_variable_from_reference\n        variable = tf.Variable(\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n"
     ]
    }
   ],
   "source": [
    "    train_ensemble_model(\n",
    "                models,\n",
    "                num_epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate, \n",
    "                max_class_count=max_class_count, \n",
    "                train_dir=train_dir, \n",
    "                model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0b618-1ff3-4b42-b0a8-013801c2355e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
